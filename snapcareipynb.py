# -*- coding: utf-8 -*-
"""SnapCareipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iFCXzZQukAT5GFtpkj1bmHNW72chgcQU
"""

#importing out neccessary modules
import torch as nn
import torchvision.datasets as datasets
from torch.utils.data import DataLoader
import torchvision
import torch
import torchvision.models as models
import torch.optim as optim

import os
os.environ["CUDA_LAUNCH_BLOCKING"] = "1"

#writing our device agnostic code
device = "cuda" if torch.cuda.is_available() else "cpu"

"""### for more information on the different transfer learning architectures look at:
https://docs.pytorch.org/vision/0.9/models.html
"""

resnet = models.resnet50(pretrained=True)

resnet

import torch.nn as nn
# we have to change the final layer because our dataset(SD-198) has 198 classes, unlike the standard 100 that resnet-50 comes with
resnet.fc = nn.Linear(in_features=resnet.fc.in_features, out_features=114)

#freeze all the layers so we won't have to train it fully
for param in resnet.parameters():
  param.requires_grad = False

#unfreeze the fully connected layer
for param in resnet.fc.parameters():
  param.requires_grad = True

#selecting our loss function and optimizers
loss_fn = torch.nn.CrossEntropyLoss()

optimizer = torch.optim.AdamW(resnet.parameters(), lr=0.001)

#importing our dataset and preparing to create a dataloader
from google.colab import drive
drive.mount('/content/drive')

import zipfile
import os

'''
We are using the dataset "SD-198" this dataset contains over 198 different skin diseases with over 6,000 images contatining images of
skin and respective disease, we downloaded the dataset from Kaggle at : https://www.kaggle.com/datasets/longngzzz/sd-198
'''

skin_data_path = '/content/drive/MyDrive/THEDATASET.zip' #this is the google drive path of the dataset
extract_path = '/content'  # Local Colab path to unzip'''


with zipfile.ZipFile(skin_data_path, 'r') as zip_ref: #this simply just extracts the zip file with data to a certain path
    zip_ref.extractall(extract_path)

from torchvision import transforms
from torch.utils.data import DataLoader,random_split # import random split for later use
from torchvision.datasets import ImageFolder
'''
train_data = transforms.Compose([
    transforms.Resize((224,224)), #resizes img to 224x224 which is what resnet uses
    transforms.ToTensor(), #transforms from PIL to Pytorch Tensor
    transforms.Normalize([0.485,0.456,0.406],
                          [0.229, 0.224, 0.225])

])'''
from torchvision import transforms
 # (left, upper, right, lower)

# Apply the cropping transform + usual preprocessing
train_data = transforms.Compose([

    transforms.Resize((224, 224)),  # resize again for model input

    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])


dataset = ImageFolder(root = "/content/THEDATASET", transform = train_data) # this is our data in the form of a Image Folder, we will have to change this into a

train_split = int(0.8*len(dataset))
testing_split = len(dataset)-train_split

train_dataset,test_dataset = random_split(dataset,[train_split,testing_split])

train_loader = DataLoader(train_dataset,batch_size = 32, shuffle = True,drop_last=True)
test_loader = DataLoader(test_dataset,batch_size = 32, shuffle = False,drop_last=True)

classes = train_dataset.dataset.classes
print(classes)
len(classes)

import matplotlib.pyplot as plt
data_iter = iter(train_loader)
images, labels = next(data_iter)
img = images[0].permute(1, 2, 0)
plt.imshow(img)

def accuracy_fn(true_values, prediction_values):
    correct = (true_values == prediction_values).sum()
    return correct.float() / true_values.size(0)  # a single scalar tensor

#importing a function previously made to measure the time
def print_train_time(start:float,
                     end:float,
                     device: torch.device = None):

  "print difference between start and end time"
  total_time = end-start
  print(f"train time on {device}: {total_time:.3f} seconds")

#making our training function

def training_steps(model: torch.nn.Module(),
                   loss_fn: torch.nn.Module(),
                   DataLoader: torch.utils.data.DataLoader,
                   optimizer : torch.optim.Optimizer,
                   accuracy,
                   device: torch.device = device
                   ):

  training_loss,training_accuracy = 0,0
  for batch, (X,y) in enumerate(tqdm(DataLoader)):
    # going throughout the batches
    X,y = X.to(device),y.to(device)


    #do the forward pass
    y_predictions = model(X)

    #calculate loss and do accuracy
    loss = loss_fn(y_predictions,y)
    training_loss +=loss #accumulating the loss so we can divde by total later

    training_accuracy += accuracy(true_values = y, prediction_values = y_predictions.argmax(dim=1)) # accumulating loss so we can divide by total later, using argmax so we can go from logits to actual predictions

    #optim zero grad
    optimizer.zero_grad()
    #backpropagation
    loss.backward()
    #optimizer step
    optimizer.step()
  true_train_loss = training_loss/len(DataLoader)
  true_train_acc = training_accuracy/len(DataLoader)
  print(f" The training loss is {true_train_loss}")
  print(f"the training accuracy is {true_train_acc}")

#making our testing function
def testing_step(model: torch.nn.Module(),
                   loss_fn: torch.nn.Module(),
                   DataLoader: torch.utils.data.DataLoader,
                   optimizer : torch.optim.Optimizer,
                   accuracy,
                   device: torch.device = device):
  testing_loss,testing_accuracy = 0,0

  model.eval()

  with torch.inference_mode():

    for X,y in DataLoader:
      X,y = X.to(device),y.to(device)

      #do the forward pass
      test_predictions = model(X)

      #test loss and test accuracy
      test_loss = loss_fn(test_predictions,y)
      testing_loss += test_loss

      testing_accuracy += accuracy(true_values = y, prediction_values = test_predictions.argmax(dim=1))
      #
    true_test_loss = testing_loss/len(DataLoader)
    true_test_accuracy = testing_accuracy/len(DataLoader)
    print(f"\n train loss: Test loss {true_test_loss}, test_acc {true_test_accuracy}")

from PIL import ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True

#training our model
from tqdm.auto import tqdm
from timeit import default_timer as timer
epochs = 25-

start_time = timer()

for i in tqdm(range(epochs)):
  print(f"Epoch: {i}")
  training_steps(
                 DataLoader = train_loader,
                 model = resnet.to(device),
                 loss_fn = loss_fn,
                 accuracy  = accuracy_fn,
                 optimizer = optimizer,
                 device = device)
  testing_step(model = resnet.to(device),
                 DataLoader = test_loader,
                 loss_fn = loss_fn,
                 accuracy  = accuracy_fn,
                 optimizer = optimizer,
                 device = device)
end_time = timer()
total = print_train_time(start = start_time,
                         end = end_time,
                         device=str(next(resnet.parameters())))
print(f"Total train time = {total}")

#Saving the model
from pathlib import Path

MODEL_Path = Path('models')
MODEL_Path.mkdir(exist_ok=True,parents=True)

MODEL_DATA = "New"
MODEL_SAVING_PATH = MODEL_Path/MODEL_DATA

print(f"Saving to {MODEL_SAVING_PATH}")
torch.save(obj = resnet.state_dict(),
           f = MODEL_SAVING_PATH)

from PIL import Image
import torchvision.transforms as transforms
import torch
import matplotlib.pyplot as plt
# Load the single image
image = Image.open("test.jpg").convert("RGB")

# Define transform pipeline (you can modify this to match your training setup)
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(
        [0.485,0.456,0.406],
                          [0.229, 0.224, 0.225]
    )
])

# Apply transform
image_tensor = transform(image).to(device)  # Shape: [3, 224, 224]

# Add batch dimension
image_tensor = image_tensor.unsqueeze(0)  # Shape: [1, 3, 224, 224]'''



print(resnet(image_tensor).argmax(dim=1))

import torch.nn as nn

new_model = models.resnet50()
new_model.fc = nn.Linear(in_features=new_model.fc.in_features, out_features = )
new_model.load_state_dict(torch.load(f=''))

print(classes[new_model(image_tensor).argmax(dim=1).item()])

output = new_model(image_tensor)

import torch.nn.functional as F

#k to get the top k predictions
K = 3

probabilites  = F.softmax(output,dim=1)

top_probs,top_idxs = torch.topk(probabilites,K)

top_probs = top_probs[0].tolist()
top_idxs = top_idxs[0].tolist()

top_classes = [classes[i] for i in top_idxs]

for i in range(K):
  print(f"Rank {i+1}:{top_classes[i]} with probability {top_probs[i]:.4f} ")